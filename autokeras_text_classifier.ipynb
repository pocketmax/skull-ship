{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOwq0q6uiuWYL2Z6L847g0g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://autokeras.com/tutorial/text_classification/\n",
        "\n"
      ],
      "metadata": {
        "id": "1lcfczXa68_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qQUHDQw5Itc"
      },
      "outputs": [],
      "source": [
        "!pip install autokeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "import autokeras as ak"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVFsjNcQ5QOM",
        "outputId": "aacb0f9c-37f9-4622-b97f-3ef5a52d1391"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "train_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=[\"pos\", \"neg\"]\n",
        ")\n",
        "test_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=[\"pos\", \"neg\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpe9izFu5bLi",
        "outputId": "5aed8795-5994-4a11-942a-746b2982b8c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 16s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data.data is a list\n",
        "train = np.array(train_data.data)\n",
        "test = np.array(test_data.data)\n",
        "# y_test = np.array(test_data.target) TODO: why was it like this?\n",
        "\n",
        "print(\"train shape:\", train.shape)\n",
        "print(\"test shape:\", test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NQAE7EdA3h7",
        "outputId": "6086156d-40b7-41af-946c-ae2be53f14d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (25000,)\n",
            "test shape: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: What does max_trials mean?\n",
        "clf = ak.TextClassifier(\n",
        "    # overwrite=True,\n",
        "    # max_trials=1\n",
        ")\n",
        "clf.fit(\n",
        "    x=train,\n",
        "    y=test,\n",
        "    # steps_per_epoch=32,\n",
        "    batch_size=16,\n",
        "    # epochs=10\n",
        ")\n",
        "print(clf.evaluate(x=train, y=test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Rz5kfT5iSM",
        "outputId": "387bc860-7ff5-4648-bf39-369ae9e34340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 06m 12s]\n",
            "val_loss: 10.6158447265625\n",
            "\n",
            "Best val_loss So Far: 10.570926666259766\n",
            "Total elapsed time: 00h 11m 52s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "bert              |vanilla           |text_block_1/block_type\n",
            "0                 |0                 |classification_head_1/dropout\n",
            "adam_weight_decay |adam              |optimizer\n",
            "2e-05             |0.001             |learning_rate\n",
            "512               |None              |text_block_1/bert_block_1/max_sequence_length\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/tokenizer.json...\n",
            "100%|██████████| 547/547 [00:00<00:00, 819kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/assets/tokenizer/vocabulary.txt...\n",
            "100%|██████████| 226k/226k [00:00<00:00, 683kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/config.json...\n",
            "100%|██████████| 510/510 [00:00<00:00, 592kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/model.weights.h5...\n",
            "100%|██████████| 418M/418M [00:11<00:00, 36.7MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/keras_nlp/src/models/backbone.py:46: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
            "/usr/local/lib/python3.10/dist-packages/keras_nlp/src/models/backbone.py:46: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "Not enough memory, reduce batch size to 8.\n",
            "Epoch 1/1000\n",
            "   1704/Unknown - 629s 361ms/step - loss: 10.1198 - accuracy: 0.0000e+00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict(np.array([\"it was amazing! the acting was perfect!\"]))"
      ],
      "metadata": {
        "id": "zzgV_Yzz0yZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(train, test, epochs=2)\n"
      ],
      "metadata": {
        "id": "vqfIrfxn5xX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextToIntSequence()(input_node)\n",
        "output_node = ak.Embedding()(output_node)\n",
        "# Use separable Conv layers in Keras.\n",
        "output_node = ak.ConvBlock(separable=True)(output_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(train, test, epochs=2)\n"
      ],
      "metadata": {
        "id": "zD1k1WJg50lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices(((train,), (test,))).batch(32)\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((train,), (test,))).batch(32)\n",
        "\n",
        "clf = ak.TextClassifier(overwrite=True, max_trials=2)\n",
        "# Feed the tensorflow Dataset to the classifier.\n",
        "clf.fit(train_set, epochs=2)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_set))\n"
      ],
      "metadata": {
        "id": "11ayl1Wk54D_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}